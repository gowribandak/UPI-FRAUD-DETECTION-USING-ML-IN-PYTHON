{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "id": "Fufvf1sh5cPu",
        "outputId": "e6e8b10a-1f50-41e5-daf5-2cbdee2cf1a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hmmlearn\n",
            "  Downloading hmmlearn-0.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.11/dist-packages (from hmmlearn) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /usr/local/lib/python3.11/dist-packages (from hmmlearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.11/dist-packages (from hmmlearn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.6.0)\n",
            "Downloading hmmlearn-0.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m165.9/165.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.3.3\n",
            "‚úÖ Dataset generated and saved as 'bengaluru_upi_transactions.csv'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_02891e18-6673-4d7d-9053-d9dd3be63d28\", \"bengaluru_upi_transactions.csv\", 89318)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üå≤ Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       258\n",
            "           1       1.00      1.00      1.00        42\n",
            "\n",
            "    accuracy                           1.00       300\n",
            "   macro avg       1.00      1.00      1.00       300\n",
            "weighted avg       1.00      1.00      1.00       300\n",
            "\n",
            "\n",
            "ü§ñ HMM Fraud Detection Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.88      0.91       250\n",
            "           1       0.47      0.66      0.55        41\n",
            "\n",
            "    accuracy                           0.85       291\n",
            "   macro avg       0.70      0.77      0.73       291\n",
            "weighted avg       0.87      0.85      0.86       291\n",
            "\n",
            "\n",
            "üîÑ Hybrid Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.88      0.89       804\n",
            "           1       0.52      0.55      0.54       187\n",
            "\n",
            "    accuracy                           0.82       991\n",
            "   macro avg       0.71      0.72      0.71       991\n",
            "weighted avg       0.82      0.82      0.82       991\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# üì¶ Import libraries\n",
        "!pip install hmmlearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from hmmlearn import hmm\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# üìç Define Bengaluru localities\n",
        "localities = {\n",
        "    'Indiranagar': {'center': (12.9716, 77.6412), 'population': 50000, 'atm_count': 30},\n",
        "    'Whitefield': {'center': (12.9698, 77.7499), 'population': 70000, 'atm_count': 25},\n",
        "    'Koramangala': {'center': (12.9352, 77.6245), 'population': 45000, 'atm_count': 35},\n",
        "    'Jayanagar': {'center': (12.9250, 77.5938), 'population': 40000, 'atm_count': 40},\n",
        "    'BTM Layout': {'center': (12.9166, 77.6101), 'population': 42000, 'atm_count': 30},\n",
        "    'Rajajinagar': {'center': (12.9915, 77.5560), 'population': 48000, 'atm_count': 28},\n",
        "    'Malleshwaram': {'center': (13.0092, 77.5695), 'population': 46000, 'atm_count': 32},\n",
        "    'Marathahalli': {'center': (12.9560, 77.7019), 'population': 55000, 'atm_count': 20},\n",
        "    'Electronic City': {'center': (12.8382, 77.6756), 'population': 60000, 'atm_count': 18},\n",
        "    'Hebbal': {'center': (13.0358, 77.5970), 'population': 48000, 'atm_count': 26}\n",
        "}\n",
        "\n",
        "# üß† Calculate fraud rates dynamically\n",
        "for data in localities.values():\n",
        "    pop, atm = data['population'], data['atm_count']\n",
        "    data['fraud_rate'] = min(0.15, 0.01 + (pop / 100000) * (1 - atm / 50))\n",
        "\n",
        "# üé≤ Generate random location around a center\n",
        "def random_location(center, radius_km=2):\n",
        "    radius_deg = radius_km / 111\n",
        "    lat_offset = np.random.uniform(-radius_deg, radius_deg)\n",
        "    lon_offset = np.random.uniform(-radius_deg, radius_deg)\n",
        "    return center[0] + lat_offset, center[1] + lon_offset\n",
        "\n",
        "# üßπ Generate a single transaction\n",
        "def generate_transaction(user_id):\n",
        "    locality = random.choice(list(localities.keys()))\n",
        "    center, fraud_prob = localities[locality]['center'], localities[locality]['fraud_rate']\n",
        "    is_fraud = np.random.rand() < fraud_prob\n",
        "    amount = np.random.uniform(100001, 500000) if is_fraud else np.random.uniform(0, 100000)\n",
        "    txn_time = datetime.now() - timedelta(minutes=np.random.randint(0, 60*24*30))\n",
        "    lat, lon = random_location(center)\n",
        "    return [user_id, round(amount, 2), lat, lon, txn_time.strftime('%Y-%m-%d %H:%M:%S'), locality, int(is_fraud)]\n",
        "\n",
        "# üìà Generate full dataset\n",
        "def generate_dataset(total_transactions=1000):\n",
        "    user_ids = [f'user_{i:04d}' for i in range(1, total_transactions // 10 + 2)]\n",
        "    data = [generate_transaction(random.choice(user_ids)) for _ in range(total_transactions)]\n",
        "    return pd.DataFrame(data, columns=['user_id', 'amount', 'latitude', 'longitude', 'transaction_time', 'locality', 'is_fraud'])\n",
        "\n",
        "# üöÄ Create and save dataset\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "dataset = generate_dataset(1000)\n",
        "dataset.to_csv('bengaluru_upi_transactions.csv', index=False)\n",
        "print(\"‚úÖ Dataset generated and saved as 'bengaluru_upi_transactions.csv'\")\n",
        "# üñ•Ô∏è Enable dataset download for your environment\n",
        "from google.colab import files\n",
        "files.download('bengaluru_upi_transactions.csv')\n",
        "\n",
        "# üìÖ Load dataset\n",
        "df = pd.read_csv('bengaluru_upi_transactions.csv')\n",
        "\n",
        "# üìè Encode locality\n",
        "df['locality'] = df['locality'].astype('category').cat.codes\n",
        "\n",
        "# ‚è∞ Extract time features\n",
        "df['transaction_time'] = pd.to_datetime(df['transaction_time'])\n",
        "df['hour'] = df['transaction_time'].dt.hour\n",
        "df['dayofweek'] = df['transaction_time'].dt.dayofweek\n",
        "\n",
        "# üîç Features and labels\n",
        "X = df[['amount', 'latitude', 'longitude', 'locality', 'hour', 'dayofweek']]\n",
        "y = df['is_fraud']\n",
        "\n",
        "# ‚úÇÔ∏è Split for Random Forest\n",
        "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# üå≤ Train Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train_rf, y_train_rf)\n",
        "\n",
        "# üß™ Evaluate Random Forest\n",
        "rf_preds = rf.predict(X_test_rf)\n",
        "print(\"\\nüå≤ Random Forest Classification Report:\")\n",
        "print(classification_report(y_test_rf, rf_preds))\n",
        "\n",
        "# ‚úÇÔ∏è Split for HMM\n",
        "X_seq = X.to_numpy()\n",
        "y_seq = y.to_numpy()\n",
        "X_seq_train, X_seq_test, y_seq_train, y_seq_test = train_test_split(X_seq, y_seq, test_size=0.3, random_state=42)\n",
        "\n",
        "# ü§ñ Train HMM\n",
        "hmm_model = hmm.GaussianHMM(n_components=2, covariance_type='diag', n_iter=100)\n",
        "hmm_model.fit(X_seq_train)\n",
        "\n",
        "# üßπ Sliding window for HMM detection\n",
        "window_size = 10\n",
        "scores, labels = [], []\n",
        "\n",
        "for i in range(0, len(X_seq_test) - window_size + 1):\n",
        "    window = X_seq_test[i:i+window_size]\n",
        "    if len(window) == window_size:\n",
        "        score = hmm_model.score(window)\n",
        "        scores.append(score)\n",
        "        fraud_ratio = y_seq_test[i:i+window_size].mean()\n",
        "        labels.append(1 if fraud_ratio > 0.2 else 0)\n",
        "\n",
        "# üéö Thresholding HMM scores\n",
        "threshold = np.percentile(scores, 20)\n",
        "hmm_preds = [1 if score < threshold else 0 for score in scores]\n",
        "\n",
        "# üß™ Evaluate HMM\n",
        "print(\"\\nü§ñ HMM Fraud Detection Classification Report:\")\n",
        "print(classification_report(labels, hmm_preds))\n",
        "\n",
        "# üîÑ Hybrid Model\n",
        "rf_final_preds = rf.predict(X)\n",
        "hmm_scores, final_labels = [], []\n",
        "\n",
        "for i in range(0, len(X) - window_size + 1):\n",
        "    window_rf_preds = rf_final_preds[i:i+window_size]\n",
        "    if len(window_rf_preds) == window_size:\n",
        "        score = hmm_model.score(X.iloc[i:i+window_size].to_numpy())\n",
        "        hmm_scores.append(score)\n",
        "        fraud_ratio = np.mean(window_rf_preds)\n",
        "        final_labels.append(1 if fraud_ratio > 0.2 else 0)\n",
        "\n",
        "# üéö Thresholding Hybrid scores\n",
        "hybrid_threshold = np.percentile(hmm_scores, 20)\n",
        "hybrid_preds = [1 if score < hybrid_threshold else 0 for score in hmm_scores]\n",
        "\n",
        "# üß™ Evaluate Hybrid Model\n",
        "print(\"\\nüîÑ Hybrid Model Classification Report:\")\n",
        "print(classification_report(final_labels, hybrid_preds))\n"
      ]
    }
  ]
}